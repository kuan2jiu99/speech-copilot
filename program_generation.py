import os
import re
import json
from openai import OpenAI
from tqdm import tqdm
import argparse


def query_pivotal_llm_for_multi_turn(client, messages, model_name="gpt-3.5-turbo", temperature=0.0, top_p=1.0, max_tokens=256, seed=1126):

    chat_completion = client.chat.completions.create(
        messages=messages,
        model=model_name,
        temperature=temperature,
        top_p=top_p,
        max_tokens=max_tokens,
        seed=seed
    )

    return chat_completion.choices[0].message.content


def speech_copilot_system_prompt(speech_module_template_path):

    # This is your decomposed speech modules generated by LLM.
    with open(speech_module_template_path, "r") as f:
        speech_module_template = f.read()
    
    # Craft the detailed guidances for Speech-Copilot.
    # The variable of `speech_module_template` is the decomposed speech modules generated by LLM.
    system_prompt = f'''\
You are an AI assistant tasked with solving user-inputted audio & speech instructions by writing Python code that utilizes the provided modules. When a user provides an instruction, follow these steps to assist them:

(1) Analyze the user's instruction and determine the tasks that need to be performed with reasons why these tasks are needed. 
(2) Identify the available modules that can be used to complete each task. The available modules are:

{speech_module_template}

(3) Write the Python code to complete the tasks using the available modules, formatted only within a main() function respectively. Do not write the additional code outside the main() function.
(4) When you determine the modules to use, please focus on the task instruction from the user only, and don't be affected by the possible options as they may vary across different tasks and users.
(5) Strictly follow the documentation of the modules and write some python comments to explain the purpose of the codes.
(6) The user will provide the required input and output for the Python code. You should only consider the input provided by the User as the arguments to the main() function.
(7) Make sure you have returned the result in the end of the main() function. Besides, you don't need to import the above modules in the code.
(8) Please provide the Python code in the below format and you must begin with ```python and end with ```. For example:
```python
def main(audio_path):
    pass
```
You can optionally express your thoughts using natural language before writing the code.
'''
    
    return system_prompt


# Save the results to the file.
def save_results(results, save_path, indent=False):
    if indent:
        with open(save_path, "w") as file:
            json.dump(results, file, indent=4)
            return
    else:
        with open(save_path, "w") as file:
            json.dump(results, file)
            return


# Save the Python code to the file.
def dump_to_python_code(python_code, save_path):
    with open(save_path, "w") as file:
        file.write(python_code)


# Extract the Python code and function name from the response.
def response_normalization(response):

    pattern = r'```python\n(.*?)```'
    matches = re.findall(pattern, response, re.DOTALL)
    
    assert len(matches) != 0, "No Python code block found in the response or Multiple Python code blocks found in the response."

    for match in matches:
        python_code = re.sub(r'# Example(?: usage)?.*$', '', match, flags=re.DOTALL | re.IGNORECASE)
        # print(python_code)
    
    pattern = r'def\s+(\w+)\s*\('
    function_name = re.search(pattern, python_code).group(1)
    
    return python_code, function_name


# Prompt template for the task with a word.
def prompt_template_with_word(instruction):
    user_prompt = f'''\
User's instruction: {instruction}

Input:
- audio_path: A string representing the file path to an audio file.
- word: A given word.

Output:
- answer: A string containing the answer selected from the options provided by the user in the instruction.

Please write a Python code according to the user instruction. The input of the function should be the content specified as "Input" and the output should be the content specified as "Output".
'''
    return user_prompt


# Prompt template for the task with text.
def prompt_template_with_text(instruction):
    user_prompt = f'''\
User's instruction: {instruction}

Input:
- audio_path: A string representing the file path to an audio file.
- text: A given text.

Output:
- answer: A string containing the answer selected from the options provided by the user in the instruction.

Please write a Python code according to the user instruction. The input of the function should be the content specified as "Input" and the output should be the content specified as "Output".
'''
    return user_prompt


# Prompt template for the usual task.
def prompt_template_usual(instruction):
    user_prompt = f'''\
User's instruction: {instruction}

Input:
- audio_path: A string representing the file path to an audio file.

Output:
- answer: A string containing the answer, selected from the options provided by the user in the instruction if specified.

Please write a Python code according to the user instruction. The input of the function should be the content specified as "Input" and the output should be the content specified as "Output".
'''
    return user_prompt


# Prompt template for the task with two audio files.
def prompt_template_two_audio(instruction):
    user_prompt = f'''\
User's instruction: {instruction}

Input:
- audio_path1: A string representing the file path to the first audio file.
- audio_path1: A string representing the file path to the second audio file.

Output:
- answer: A string containing the answer, selected from the options provided by the user in the instruction if specified.

Please write a Python code according to the user instruction. The input of the function should be the content specified as "Input" and the output should be the content specified as "Output".
'''
    return user_prompt


# Get the prompt template based on the type of the task.
def prompt_template(instruction):

    # If your task involves multiple audio files, you can use the prompt_template_two_audio function.
    # prompt = prompt_template_two_audio(instruction)

    # If your task involves a word, you can use the prompt_template_with_word function.
    # prompt = prompt_template_with_word(instruction)

    # Otherwise, you can use the prompt_template_usual function.
    prompt = prompt_template_usual(instruction)

    return prompt


def main(args):

    client = OpenAI(api_key=args.openai_api_key)

    system_prompt = speech_copilot_system_prompt(speech_module_template_path=args.speech_module_template_path)
   
    user_prompt = prompt_template(instruction=args.instruction)
    print(f"User Prompt:\n {user_prompt}")

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    # The program generated by the model
    solutions = query_pivotal_llm_for_multi_turn(client=client, messages=messages, model_name=args.model_name, temperature=args.temperature, top_p=args.top_p, max_tokens=args.max_tokens)
    print(f"Solution generated by the LLM:\n {solutions}")

    # Extract the Python code and function name from the response
    python_code, function_name = response_normalization(response=solutions)
    print(f"Python code:\n {python_code}")

    # Save the Python code to the file.
    save_task_name = args.task_name.split("/")[-1]
    python_code_save_dir = f"{args.save_path}/{save_task_name}"

    if not os.path.exists(python_code_save_dir):
        os.makedirs(python_code_save_dir)
    
    dump_to_python_code(python_code=python_code, save_path=f"{python_code_save_dir}/{function_name}.py")



if __name__ == "__main__":

    parser = argparse.ArgumentParser()

    # Take the Dynamic-SUPERB Phase1 task for example, DynamicSuperb/EmotionRecognition_MultimodalEmotionlinesDataset.
    # DynamicSUPERB on Hugging Face: https://huggingface.co/DynamicSuperb
    # Sample instruction in Dynamic-SUPERB Phase1 task "EmotionRecognition_MultimodalEmotionlinesDataset": "Recognize and organize the emotional expressions in the spoken words. The answer could be anger, disgust, sadness, joy, neutral, surprise, or fear."
    parser.add_argument("--instruction", type=str, help="The user instruction.", default="Recognize and organize the emotional expressions in the spoken words. The answer could be anger, disgust, sadness, joy, neutral, surprise, or fear.")
    
    # Decomposed speech modules generated by LLM, default path is "./prompt_templates/speech_module_generated_by_LLM.py", you can change it to your own path.
    parser.add_argument("--speech_module_template_path", type=str, help="The path to the decomposed speech modules generated by LLM.", default="./prompt_templates/speech_module_generated_by_LLM.py")

    # Pivotal LLM model name and sampling parameters.
    parser.add_argument("--model_name", type=str, help="The Pivotal LLM model name.", default="gpt-4o-2024-05-13")
    parser.add_argument("--temperature", type=float, help="The temperature for sampling.", default=0.0)
    parser.add_argument("--top_p", type=float, help="The top_p for sampling.", default=0.9)
    parser.add_argument("--max_tokens", type=int, help="The maximum number of tokens to generate.", default=1024)
    parser.add_argument("--openai_api_key", type=str, help="The OpenAI API key", required=True)

    # Generated program save path.
    parser.add_argument("--save_path", type=str, help="The save directory for the generated program.", default="./generated_program")

    # Random seed.
    parser.add_argument("--seed", type=int, help="Random seed", default=1126)

    args = parser.parse_args()

    main(args)